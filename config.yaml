
# settings specific to camera handling
camera:
  # camera id for cv::VideoCapture constructor (probably '0' if only one camera is present)
  camId: 0

# settings for audio capture/playback
audio:

  aiActivationWord: "chat"
  cmdActivationWord: "camera"

  #set either to false to perform online speech recognition before final processing
  cmdLocalSpeechDetectOnly: true
  aiLocalSpeechDetectOnly: true


  #microphone device to use
  device: "default"

  echoSpeech: false


  #microphone samples per second
  samplesPerSec: 16000
  #how many samples between each check for speech
  #also means minimum silence required to detect end of speech
  samplesPerCheck: 8000

whisper:
  vadModel: "./models/ggml-silero-v5.1.2.bin"
  vadThreshold: 0.95
  model: "./models/ggml-base.en.bin"
  maxThreads: 6

espeak:
  data: "./build/espeak/src/espeakng-build/espeak-ng-data"
  model: "./models/en_GB-cori-medium.onnx"

#settings for openai integration
openai:
  #full path to file containing the openai api key
  keyFile: "./oai_key"

  #for different types of requests different openai models can be used a various speed and price options
  #Details of models available can be found here: https://platform.openai.com/docs/models

  #ai model to use for text to audio api requests (must support audio output)
  model: "gpt-4o-mini-audio-preview"
  #ai model to use for speech to text requests (must support transcribe operation)
  transcribeModel: "gpt-4o-mini-transcribe"
  #ai model to use for image analysing (will not also support audio output currently)
  imageModel: "gpt-4.1-mini"
  #ai moddel to use for text to speech requests
  ttsModel: "gpt-4o-mini-tts"

  #openai voice to use for speech output (openai supports several voices: https://platform.openai.com/docs/guides/text-to-speech)
  voice: "nova"

  #if these words appear in the AI request text, the current image frame will be included
  imageInclusionKeywords:
    - "image" #e.g. describe this image
    - "seeing" #e.g. describe what I am seeing
    - "photo" #e.g. what is in this photo?
    - "looking" #e.g. what am i looking at?
    - "picture" #e.g. what is in this picture?

#settings for vision
RoboRob:

  # these words are to trigger the commands
  # there must be a space before and after to make sure we don't match a partial word
  zoomin: " in "
  zoomout: " out "
  edges: " edges "
  normal: " normal "
  contrast: " contrast "
  more: " more "
  less: " less "
  flip: " flip "
  help: " help "

  # way to set the volume. no spaces needed here
  volume: "100%"

#options to control log output
logging:
  logToConsole: true
  logToFile: true
  logFile: "./glasses.log"
